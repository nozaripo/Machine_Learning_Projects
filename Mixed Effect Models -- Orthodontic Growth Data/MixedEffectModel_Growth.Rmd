---
title: 'Linear Mixed Effect Model for Orthodontic Growth Data'
author: "Pouria"
date: "28 February, 2022"
output:
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



# Objective
In this project, the objective is to infer an ML model that can fit to the longitudinal Orthodontic Growth dataset. The independent variables of interest in this set are `age`, `gender`, and `sex`. In this project, we seek to find the most important factors among these and also see if we need a model beyond linear regression to explain the data.




# Required Libraries

```{r, warning=F, message=F}
library(nlme)
library(ggplot2)
library(dplyr)
library(tidyr)
library(magrittr)
```



# Into to "Orthodontic growth" dataset

**Orthodontic growth data, Example from Pinheiro and Bates (2000)**

Investigators at the University of North Carolina Dental School followed the growth of 27 children(16 males, 11 females) from age 8 until age 14. Every two years they measured the distance between the pituitary and the pterygomaxillary fissure, two points that are easily identified on xray exposures of the side of the head.

```{r}
attach(Orthodont)
head(Orthodont)
```

# Questions

- Is there an age effect on growth?

- Is there a gender difference?

- Is growth different in both sexes (Is there
an interaction)?

- Is an ordinary linear regression model
adequate?

## Specific questions

1. Take a look at the data in group and per subject. (`distance` vs. `age`)

2. How would a one-fits-all model do? (only `age` effect present)

- Plot the residuals vs. fitted values in a scatterplot

- Plot the residuals per subject in a boxplot

3. Use independent linear models per subject;
- Summarize

- Plot the coefficients intervals

- Plot the fits per subject

4. Discuss considering `Subject` effect in the model.

5. Fit a mixed effect model to the data for `age` as the fixed effect and `Subject` as the random

- Use general, diagonal and only-slope covariance matrix structures, show the effects coefficients intervals and decide which one to pick using anova.

- Plot the mixed-effect model coefficients against those from the fixed-effect

- Plot mixed-effect fits for each subject

6. Consider `Sex` and its interaction with `age` as other effecs. Is it a signficant variable in predicting the `distance`?

- Plot residuals vs. fitted-values for mixed-effect and fixed-effect models.

- Plot residuals per subject (in form of box plots)

- Compare mixed effect model and fixed effect model using anova

- Check out the coefficients in fixed-effect and random-effects


# Preliminary Visualization

Let's plot the data per subject

```{r}
ggplot(Orthodont) +
  geom_point(aes(x = age, y = distance)) +
  geom_line(aes(x = age, y = distance), color="blue") +
  facet_wrap (~Subject) +
  xlab("Age (yr)") + 
  ylab("Distance from pituitary to pterygomaxillary fissure (mm)") +
  theme_bw()
```

Now plot the data in a scatter-plot

```{r}
ggplot(Orthodont) +
  geom_point(aes(x = age, y = distance, col = Sex)) +
  xlab("Age (yr)") + 
  ylab("Distance from pituitary to pterygomaxillary fissure (mm)") +
  scale_color_manual(values=c("black", "red")) +
  theme_bw()
```


# Data Modeling Part 1: Simple Linear Regression to fit all

### Does one model fit all?
Let's see. In order to do this, the assumption is that there is no significant effect of `Subject`. Thus, we will have:

$$y_j^{(i)} = \beta_0 + \beta_1 * age_j^{(i)} + \epsilon_j^{(i)}$$
where 

Subject_ID:   $i=1,..., M  \qquad (M=27)$   

Year_ID:      $j=1,..., N  \qquad (N=4)$  

residuals:    $\epsilon_j^{(i)} = \cal N(0,\sigma^2)$


Let's code the one-fits-all linear regression up:

```{r}
lm.fit_all <- lm(distance ~ I(age-11)*Sex, Orthodont)
summary(lm.fit_all)
```


Below, we will take a look at the residuals of the mode.

```{r}
ggplot(lm.fit_all) +
  geom_point(aes(x = .fitted, y = .resid, col = Sex)) +
  scale_color_manual(values=c("black", "red")) +
  xlab("Fitted Values") + ylab("Standardized Residuals") +
  theme_bw()
```

At first glance, the residuals seem to be homoscedastic. However, we cannot really tell much from this plot. Importantly, if the effect of `Subject` is non-existent, then the residuals across different subjects should not differ. Let's see if that is the case: 


## Residuals for each subject

```{r}
ggplot(lm.fit_all) +
  geom_boxplot(aes(x = Subject, y = .resid, col = Sex)) +
  scale_color_manual(values=c("black", "red")) +
  xlab("Subject") + ylab("Standardized Residuals") +
  theme_bw()
```

Looks like the one-fits-all model did not do a good job fitting onto everyone's data. This means the effect of `Subject` should be considered in our modeling process. But how?

Well, one way to do this is fit an independent model per subject. We will do that in the following:


# Data Modeling Part 2: Simple Linear Regression Per Subject

## Fit the model:
Use `lmList(.)`

** `age` as the only covariate **

```{r}
lm.fit_perSubj <- lmList(distance ~ I(age-11) | Subject, Orthodont)

summary(lm.fit_perSubj)
```

## Plot 95% confidence intervals

intercept and slope for each subject

```{r}
coef.95.perSubj <- intervals(lm.fit_perSubj)
plot(coef.95.perSubj)

```

## Plot fits for each subject

```{r}
ggplot(Orthodont, aes(x = age, y = distance)) + 
  geom_point() +
  geom_smooth(method="lm") +
  facet_wrap(~Subject) +
  theme_bw()
```







## Comments

- Residuals corresponding to the same subject tend to have the same sign.

- There is a significant subject-to-subject variability for intercept.

- Need to incorporate a “subject effect” in the model to account for between-subject variability.




## What if we use `Subject` as an actual effect?

- Inference about subject effect will not be applicable to the whole population

- You would still need M-1 dummy variables

### e.g. use dummy variables for `Subject` effect

```{r}
lm.fit_SubjVariable <- lm(distance ~ I(age-11)*Subject, data = Orthodont)
summary(lm.fit_SubjVariable)
```


The most important conclusion of this section is that how can you achieve any interpretable insights about the data or even the effect of `Subject` variable if you fit one independent regression model for each subject.

The solution to this has been proposed by the Statisticians and Scientists:

**Linear Mixed Effect Model**


# Data Modeling Part 3: Fit a Linear Mixed Effect Model (LME)

$$y_j^{(i)} = \quad \\
\beta_0 + \beta_1 * age_j^{(i)} + \qquad \\
                  b_0^{(i)} + b_1^{(i)} * age_j^{(i)} + \quad \epsilon_j^{(i)}$$

where 

$$\begin{bmatrix}
b_0^{(i)}\\ b_1^{(i)}
\end{bmatrix} = \cal N(\mathbf{0}, \mathbf{\Psi}),\quad  \mathbf{\Psi} = \begin{bmatrix}
\sigma_0^2 & \rho\sigma_0\sigma_1\\ \rho\sigma_0\sigma_1 & \sigma_1^2
\end{bmatrix}$$

Subject_ID:   $i=1,..., M  \qquad (M=27)$   

Year_ID:      $j=1,..., N  \qquad (N=4)$  

residuals:    $\epsilon_j^{(i)} = \cal N(0,\sigma^2)$

random effects: $b_0^{(i)}$ and $b_1^{(i)}$


What a linear mixed effect model does is that in this case, it takes into accounts the effect of `Subject` but does not fit independent models for each subject. Instead, it allows for a between-subject variability through a Gaussian process. As a result, the outcome model instead of having `M-1` levels of parameters to represent `M` subjects, has at most 3 parameters; the diagonal and off-diagonal noise/variance values in the covariance matrix.


## Fit a single-level mixed effect model

Both intercept and slope

```{r}
lm.fit_mixed_all <- lme(distance~I(age-11), data=Orthodont, random=~I(age-11)|Subject)

summary(lm.fit_mixed_all)
```

## Confidence interval of the fit

```{r}
intervals(lm.fit_mixed_all)
```

## Mixed Effect with diagonal covariance

```{r}
lm.fit_mixed_diag <- lme( distance~I(age-11), data=Orthodont, 
                         random=list( Subject = pdDiag( ~I(age-11) ) ) )
lm.fit_mixed_diag
```


## Compare general and diagonal models

```{r}
anova( lm.fit_mixed_all, lm.fit_mixed_diag)
```


## Mixed Effect with only slope as random effect

```{r}
lm.fit_mixed_slope <- lme( distance~I(age-11), data=Orthodont, 
                         random=~I(age-11)-1|Subject )
lm.fit_mixed_slope
```

## Compare general and mixed-effects-only-slope models

```{r}
anova( lm.fit_mixed_diag, lm.fit_mixed_slope)
```

## Compare the coefficients between the mixed-effect and list models


```{r}
df.mixed <- data.frame(coef(lm.fit_mixed_diag)) %>%
  set_colnames(c("Intercept", "Slope")) %>%
  pivot_longer(cols=1:2, names_to = "coeff_type", values_to ="coeff" )
data.coef.mixed <- data.frame(df.mixed, levels(Subject))

df.list<- data.frame(coef(lm.fit_perSubj)) %>%
  set_colnames(c("Intercept", "Slope")) %>%
  pivot_longer(cols=1:2, names_to = "coeff_type", values_to ="coeff" )
data.coef.list <- data.frame(df.list, levels(Subject))

data.coef.both <- rbind(data.coef.mixed, data.coef.list) %>%
  mutate(model = rbind(matrix(rep("Mixed-effect",54),nrow = 54) , matrix(rep("lmList",54), nrow = 54))) %>%
  set_colnames(c("coeff_type", "coeff", "Subject", "Model"))


ggplot(data.coef.both) +
  geom_point(aes(y = Subject, x = coeff, col = Model)) +
  facet_wrap(~coeff_type, scales = 'free_x') +
  scale_color_manual(values=c("black", "red")) +
  xlab("Fitted Values") + ylab("Standardized Residuals") +
  theme_bw()

```

## Plot mixed effect fits for each subject

```{r}
newdata <- crossing(
  Subject = Orthodont %>% pull(Subject) %>% levels() %>% factor(),
  age = c(8,10,12,14))
newdata2 <- newdata %>%
  mutate(distance = predict(lm.fit_mixed_diag, newdata))


ggplot(Orthodont, aes(x = age, y = distance)) +
  geom_point() +
  facet_wrap(~Subject) +
  geom_line(data = newdata2, color = 'blue') +
  labs(y = "Distance (mm)", x = "Age (yr)") +
  theme_bw()

```

## Consider the gender as an effect (Summarize)

```{r}
lm.fit_sex_mixed_all <- lme(distance~I(age-11)*Sex, data=Orthodont, random=~I(age-11)|Subject)
summary(lm.fit_sex_mixed_all)

```


## Consider the gender as an effect (Check Intervals)

```{r}
intervals(lm.fit_sex_mixed_all)

```

## Residual Plot vs. fitted value

```{r}
Data_mixedeffect <- Orthodont %>%
  mutate(fit = fitted(lm.fit_sex_mixed_all),
       resid = residuals(lm.fit_sex_mixed_all))

ggplot(Data_mixedeffect) +
  geom_point(aes(x = fit, y = resid, col = Sex)) +
  scale_color_manual(values=c("black", "red")) +
  xlab("Fitted Values") + ylab("Standardized Residuals") +
  theme_bw()

```

## Residuals for each subject (boxplot)
```{r}
ggplot(Data_mixedeffect) +
  geom_boxplot(aes(x = Subject, y = resid, col = Sex)) +
  scale_color_manual(values=c("black", "red")) +
  geom_hline(aes(yintercept = 0)) +
  xlab("Subject") + ylab("Standardized Residuals") +
  theme_bw()

  
```



## Compare mixed effect model and fixed effect model

```{r}
anova(lm.fit_sex_mixed_all, lm.fit_all)
```


## Check the fixed-effect and random-effect coefficients

```{r}
ran.eff <- random.effects(lm.fit_sex_mixed_all)
fix.eff <- fixed.effects(lm.fit_sex_mixed_all)

ran.eff

fix.eff
```


## Plot the fixed and mixed effects fits on the same graph per subject

```{r}

coeffs.model.mixed <- matrix(rep(0,54), nrow = 27)
coeffs.model.fixed <- matrix(rep(0,54), nrow = 27)


coeffs.model.fixed[1:16,1] <- fix.eff[1]
coeffs.model.fixed[1:16,2] <- fix.eff[2]
coeffs.model.fixed[16:27,1] <- fix.eff[1]+ fix.eff[3]
coeffs.model.fixed[16:27,2] <- fix.eff[2]+ fix.eff[4]

coeffs.model.mixed[1:16,1] <- ran.eff[1:16,1] + fix.eff[1]
coeffs.model.mixed[1:16,2] <- ran.eff[1:16,2] + fix.eff[2]
coeffs.model.mixed[17:27,1]<- ran.eff[17:27,1] + fix.eff[1]+ fix.eff[3]
coeffs.model.mixed[17:27,2]<- ran.eff[17:27,2] + fix.eff[2]+ fix.eff[4]


ids <- Orthodont %>% pull(Subject) %>% levels() %>% factor()

# make a tibble with the data extracted above
coeffs.model.fixed <- tibble(Subject = ids,
                  intercept = coeffs.model.fixed[,1],
                  slope = coeffs.model.fixed[,2])

coeffs.model.mixed <- tibble(Subject = ids,
                  intercept = coeffs.model.mixed[,1],
                  slope = coeffs.model.mixed[,2])

```



```{r, include=TRUE}
ggplot(Orthodont, aes(x = I(age-11), y = distance)) +
  geom_abline(data = coeffs.model.fixed, aes(intercept = intercept, 
                  slope = slope, col="Fixed Effect"), size = 1.3) +
  geom_abline(data = coeffs.model.mixed, aes(intercept = intercept, 
                  slope = slope, col="Mixed Effect"), size = 1.3) +
  geom_point() +
  facet_wrap(~Subject) +
  labs(x = "Age-11", y = "Distance", color = "Model") +
  scale_color_manual(values = c("blue", "red")) +
  theme_bw()

```



# Conclusion
We saw that to infer a model that fits the data from different subjects, we sometimes need to consider the effect of between-subject variability. In this project, we took the opportunity to familiarize ourselves with one of the most powerful methods that does this; linear mixed effect model. We saw that a simple one-fits-all model did not do a great job in explaining the data from all subjects, while a one-model-per-subject method had too many parameters in the model to estimate compromising the interpretability of the outcome model. The solution to the rescue was a linear mixed effect model. After using a linear mixed effect model, we saw that the residuals across all individuals's data were homoscedastic and also the model was still interpretable since the number of parameters to find in this model was small.
